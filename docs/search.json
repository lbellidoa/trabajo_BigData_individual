[
  {
    "objectID": "my_trabajo_BigData.html",
    "href": "my_trabajo_BigData.html",
    "title": "El mejor libro",
    "section": "",
    "text": "Para este trabajo vamos a estar utilizando datos sobre libros en Goodreads y sus notas, estos se pueden sacar de aquí. También utilizaremos datos sobre el número de hablantes de cada idioma que se pueden encontrar aquí\nLos datos se pueden cargar en la memoria de de R/RStudio de esta forma:\n\nCódigolibrary(readr)\ngoodreads &lt;- read_csv(\"data/goodreads.csv\")\nhablantes &lt;- read_csv(\"data/Top 100 Languages.csv\")\n\n\nY descargamos la biblioteca:\n\nCódigolibrary(gt)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(viridis)\nlibrary(hrbrthemes)\nlibrary(highcharter)"
  },
  {
    "objectID": "my_trabajo_BigData.html#intro",
    "href": "my_trabajo_BigData.html#intro",
    "title": "El mejor libro",
    "section": "",
    "text": "Vamos a utilizar datos del paquete palmerpenguins. El repo del paquete en CRAN está aquí, el repo de Github está aquí y la página web del paquete está aquí.\nLos datos se pueden cargar en la memoria de de R/RStudio de esta forma:\n\nCódigo# install.packages(\"palmerpenguins\")\nlibrary(palmerpenguins)\ndf &lt;- palmerpenguins::penguins\n\n\nEl dataset contiene observaciones sobre un conjunto de 344 pingüinos de 3 especies. Hay 8 variables."
  },
  {
    "objectID": "my_trabajo_BigData.html#los-pingüinos-molan",
    "href": "my_trabajo_BigData.html#los-pingüinos-molan",
    "title": "El mejor libro",
    "section": "Los pingüinos molan",
    "text": "Los pingüinos molan\nVamos a ver una foto de un pingüinos\n\n\nUn pingüino chulo\n\n\nSí, lo pingüinos molan, así que vamos a poner otra foto de pingüinos que tenemos en nuestro PC pero la vamos a poner en el margen:"
  },
  {
    "objectID": "my_trabajo_BigData.html#algunos-gráficos",
    "href": "my_trabajo_BigData.html#algunos-gráficos",
    "title": "El mejor libro",
    "section": "Algunos gráficos",
    "text": "Algunos gráficos\nBueno pues vamos a hacer algún gráfico, pero claro antes he de cargar los paquetes\n\nCódigolibrary(tidyverse)\n\n\nArreglo los datos\n\nCódigo#- cojos datos de pingüinos y arreglo un poco \ndf &lt;- palmerpenguins::penguins %&gt;% \n  dplyr::select(species, bill_depth_mm, body_mass_g) %&gt;% \n  tidyr::drop_na()\n\n\n\nPrimer gráfico\n\nCódigo#- primer gráfico\np &lt;- ggplot(data = df, \n       mapping = aes(x = bill_depth_mm, y = body_mass_g, color = species)) +\n     geom_point()\np\n\n\n\n\n\n\n\nSegundo\n\nCódigo#- segundo gráfico\np &lt;- p + geom_smooth(method = \"lm\", se = FALSE) \n\np\n\n\n\n\n\n\n\nEl último\n\nCódigo#- tercer gráfico\np + geom_smooth(method = \"lm\", se = FALSE, color = \"black\") \n\n\n\n\n\n\n\n\nCon esto acabo mi trabajo para BigData!!\n\n\n\nInformación sobre la sesión\nAbajo muestro mi entorno de trabajo y paquetes utilizados\n\n\n current session info \n\n─ Session info ───────────────────────────────────────────────────────────────\n setting  value\n version  R version 4.5.1 (2025-06-13 ucrt)\n os       Windows 11 x64 (build 26200)\n system   x86_64, mingw32\n ui       RTerm\n language (EN)\n collate  Spanish_Spain.utf8\n ctype    Spanish_Spain.utf8\n tz       Europe/Madrid\n date     2025-12-19\n pandoc   3.4 @ C:/Program Files/RStudio/resources/app/bin/quarto/bin/tools/ (via rmarkdown)\n quarto   NA @ C:\\\\Users\\\\lucib\\\\AppData\\\\Local\\\\Programs\\\\Quarto\\\\bin\\\\quarto.exe\n\n─ Packages ───────────────────────────────────────────────────────────────────\n package        * version date (UTC) lib source\n cli              3.6.5   2025-04-23 [1] CRAN (R 4.5.1)\n clipr            0.8.0   2022-02-22 [1] CRAN (R 4.5.1)\n desc             1.4.3   2023-12-10 [1] CRAN (R 4.5.1)\n details          0.4.0   2025-02-09 [1] CRAN (R 4.5.2)\n digest           0.6.37  2024-08-19 [1] CRAN (R 4.5.1)\n dplyr          * 1.1.4   2023-11-17 [1] CRAN (R 4.5.1)\n evaluate         1.0.5   2025-08-27 [1] CRAN (R 4.5.1)\n farver           2.1.2   2024-05-13 [1] CRAN (R 4.5.1)\n fastmap          1.2.0   2024-05-15 [1] CRAN (R 4.5.1)\n forcats        * 1.0.0   2023-01-29 [1] CRAN (R 4.5.1)\n generics         0.1.4   2025-05-09 [1] CRAN (R 4.5.1)\n ggplot2        * 4.0.0   2025-09-11 [1] CRAN (R 4.5.1)\n glue             1.8.0   2024-09-30 [1] CRAN (R 4.5.1)\n gtable           0.3.6   2024-10-25 [1] CRAN (R 4.5.1)\n hms              1.1.3   2023-03-21 [1] CRAN (R 4.5.1)\n htmltools        0.5.8.1 2024-04-04 [1] CRAN (R 4.5.1)\n htmlwidgets      1.6.4   2023-12-06 [1] CRAN (R 4.5.1)\n httr             1.4.7   2023-08-15 [1] CRAN (R 4.5.1)\n jsonlite         2.0.0   2025-03-27 [1] CRAN (R 4.5.1)\n knitr            1.50    2025-03-16 [1] CRAN (R 4.5.1)\n labeling         0.4.3   2023-08-29 [1] CRAN (R 4.5.0)\n lattice          0.22-7  2025-04-02 [2] CRAN (R 4.5.1)\n lifecycle        1.0.4   2023-11-07 [1] CRAN (R 4.5.1)\n lubridate      * 1.9.4   2024-12-08 [1] CRAN (R 4.5.1)\n magrittr         2.0.3   2022-03-30 [1] CRAN (R 4.5.1)\n Matrix           1.7-3   2025-03-11 [2] CRAN (R 4.5.1)\n mgcv             1.9-3   2025-04-04 [2] CRAN (R 4.5.1)\n nlme             3.1-168 2025-03-31 [2] CRAN (R 4.5.1)\n palmerpenguins * 0.1.1   2022-08-15 [1] CRAN (R 4.5.1)\n pillar           1.11.1  2025-09-17 [1] CRAN (R 4.5.1)\n pkgconfig        2.0.3   2019-09-22 [1] CRAN (R 4.5.1)\n png              0.1-8   2022-11-29 [1] CRAN (R 4.5.0)\n purrr          * 1.1.0   2025-07-10 [1] CRAN (R 4.5.1)\n R6               2.6.1   2025-02-15 [1] CRAN (R 4.5.1)\n RColorBrewer     1.1-3   2022-04-03 [1] CRAN (R 4.5.0)\n readr          * 2.1.5   2024-01-10 [1] CRAN (R 4.5.1)\n rlang            1.1.6   2025-04-11 [1] CRAN (R 4.5.1)\n rmarkdown        2.29    2024-11-04 [1] CRAN (R 4.5.1)\n rstudioapi       0.17.1  2024-10-22 [1] CRAN (R 4.5.1)\n S7               0.2.0   2024-11-07 [1] CRAN (R 4.5.1)\n scales           1.4.0   2025-04-24 [1] CRAN (R 4.5.1)\n sessioninfo      1.2.3   2025-02-05 [1] CRAN (R 4.5.1)\n stringi          1.8.7   2025-03-27 [1] CRAN (R 4.5.0)\n stringr        * 1.5.2   2025-09-08 [1] CRAN (R 4.5.1)\n tibble         * 3.3.0   2025-06-08 [1] CRAN (R 4.5.1)\n tidyr          * 1.3.1   2024-01-24 [1] CRAN (R 4.5.1)\n tidyselect       1.2.1   2024-03-11 [1] CRAN (R 4.5.1)\n tidyverse      * 2.0.0   2023-02-22 [1] CRAN (R 4.5.1)\n timechange       0.3.0   2024-01-18 [1] CRAN (R 4.5.1)\n tzdb             0.5.0   2025-03-15 [1] CRAN (R 4.5.1)\n vctrs            0.6.5   2023-12-01 [1] CRAN (R 4.5.1)\n withr            3.0.2   2024-10-28 [1] CRAN (R 4.5.1)\n xfun             0.53    2025-08-19 [1] CRAN (R 4.5.1)\n yaml             2.3.10  2024-07-26 [1] CRAN (R 4.5.0)\n\n [1] C:/Users/lucib/AppData/Local/R/win-library/4.5\n [2] C:/Program Files/R/R-4.5.1/library\n * ── Packages attached to the search path.\n\n──────────────────────────────────────────────────────────────────────────────"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lucía Bellido",
    "section": "",
    "text": "Hola, soy Lucía Bellido\nEsta web sirve para presentar el trabajo final individual para la asignatura “Programación y manejo de datos en la era Del Big Data”, optativa de GECO en la Facultad de Economía de la Universitat de València.\nLa web de la asignatura está aquí y los trabajos de mis compañeros de curso puedes verlos aquí.\nMi trabajo lleva por título : “El mejor libro”. El objetivo es crear el mejor libro posible basándonos en las reseñas de los usuarios de la aplicación Goodreads.\nEl trabajo puede verse aquí.\n\n\nReutilizarCC BY 4.0"
  },
  {
    "objectID": "my_trabajo_BigData.html#introducción",
    "href": "my_trabajo_BigData.html#introducción",
    "title": "El mejor libro",
    "section": "",
    "text": "Para este trabajo vamos a estar utilizando datos sobre libros en Goodreads y sus notas, estos se pueden sacar de aquí. También utilizaremos datos sobre el número de hablantes de cada idioma que se pueden encontrar aquí\nLos datos se pueden cargar en la memoria de de R/RStudio de esta forma:\n\nCódigolibrary(readr)\ngoodreads &lt;- read_csv(\"data/goodreads.csv\")\nhablantes &lt;- read_csv(\"data/Top 100 Languages.csv\")\n\n\nY descargamos la biblioteca:\n\nCódigolibrary(gt)\nlibrary(tidyverse)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(viridis)\nlibrary(hrbrthemes)\nlibrary(highcharter)"
  },
  {
    "objectID": "my_trabajo_BigData.html#qué-libros-le-gusta-a-la-gente",
    "href": "my_trabajo_BigData.html#qué-libros-le-gusta-a-la-gente",
    "title": "El mejor libro",
    "section": "¿Qué libros le gusta a la gente?",
    "text": "¿Qué libros le gusta a la gente?\nEmpezaremos con un gráfico de burbujas para observar qué libros han tenido más éxito, obteniendo mayores notas medias.\n\nCódigoburbujas &lt;- goodreads %&gt;% \n  mutate (anio = str_extract(publication_date, \"\\\\d{4}$\")) %&gt;% \n  drop_na () %&gt;% \n  arrange (desc(average_rating)) %&gt;%\n  filter (average_rating &gt;= 4.65)\n\np &lt;- burbujas %&gt;%\n  mutate (language_code = factor(language_code, levels = unique(language_code))) %&gt;%\n  mutate (text = paste(\"Libro: \", title,\n                       \"\\nIdioma: \", language_code, \n                       \"\\nNota: \", average_rating, \n                       \"\\nAño: \", anio, \n                       \"\\nNúmero de votos: \", \n                       ratings_count, sep=\"\")) %&gt;%\n  ggplot (aes(x = anio, y = average_rating, size = ratings_count, color = language_code, text=text)) +\n    geom_point (alpha = 0.7) +\n    scale_size (range = c(1.4, 19), name = \"Nº votos\") +\n    scale_color_viridis (discrete = TRUE, guide = FALSE) +\n    theme_ipsum () +\n    theme (legend.position = \"none\") +\n  labs (title = \"Libros con mejor media\",\n        x = \"Año\", y = \"Nota media\")\n\npp &lt;- ggplotly (p, tooltip=\"text\") \n\npp\n\n\n\n\n\nCodigo inspirado en este.\nComo se puede observar, muchos libros con una puntuación de 5 sobre 5 tienen muy pocas reviews, por lo que vamos a descartarlos y poner un mínimo de 10.000 reviews para elaborar un top 10 más preciso. También eliminaremos las sagas para centrarnos únicamente en libros individuales.\n\nCódigotop_libros &lt;- goodreads %&gt;% \n  filter (ratings_count &gt;= 10000) %&gt;% \n  filter (!str_detect(title, regex(\"\\\\bset\\\\b\", ignore_case = TRUE))) %&gt;% \n  filter (!str_detect(title, regex(\"\\\\bcollection\\\\b\", ignore_case = TRUE))) %&gt;% \n  select (title, authors, average_rating) %&gt;% \n  arrange (desc(average_rating)) %&gt;%\n  head(10)\n\nDT::datatable(top_libros)\n\n\n\n\n\nPodemos observar que la saga “Calvin and Hobbes” de Bill Watterson tiene un gran éxito en Goodreads y que la mayoría de libros en el top son cómics o mangas. Además, aparecen sagas muy conocidas como “Harry Potter” y “El señor de los anillos”."
  },
  {
    "objectID": "my_trabajo_BigData.html#quién-debería-escribir-nuestro-libro",
    "href": "my_trabajo_BigData.html#quién-debería-escribir-nuestro-libro",
    "title": "El mejor libro",
    "section": "¿Quién debería escribir nuestro libro?",
    "text": "¿Quién debería escribir nuestro libro?\nPara continuar formando el mejor libro, vamos a ver qué autores tienen mejor nota media filtrando también con más de 10.000 reviews y que sean libros individuales.\n\nCódigotop_autores &lt;- goodreads %&gt;% \n  filter (ratings_count &gt;= 10000) %&gt;% \n  filter (!str_detect(title, regex(\"\\\\bset\\\\b\", ignore_case = TRUE))) %&gt;% \n  filter (!str_detect(title, regex(\"\\\\bcollection\\\\b\", ignore_case = TRUE))) %&gt;% \n  group_by (authors) %&gt;% \n  summarise (nota_media = weighted.mean(average_rating, w = ratings_count)) %&gt;% \n  arrange (desc(nota_media)) %&gt;%\n  head (10) %&gt;% \n  mutate (autores = str_trunc(authors, 20)) %&gt;%\n  ungroup ()\n\np2 &lt;- ggplot (top_autores, aes(x = nota_media, y = reorder(autores, nota_media))) + \n  geom_col (fill = \"#7831a2\") +\n  coord_cartesian (xlim = c(4, 5)) +\n  labs (title = \"Autores con mejor media\", \n        x = \"Nota media\", y = \"Autores\")\n\np2\n\n\n\n\n\n\n\nSe puede observar, como se esperaba al ver el top 10 de libros, que el autor con mejor nota media es Bill Watterson. Aunque también podemos ver a Neil Gaiman en tres posiciones diferentes del top, al tratarse de él junto a muchos otros autores, preferimos quedarnos con B. Watterson para que se trate únicamente de un autor."
  },
  {
    "objectID": "my_trabajo_BigData.html#cuántas-páginas-debe-tener-nuestro-libro",
    "href": "my_trabajo_BigData.html#cuántas-páginas-debe-tener-nuestro-libro",
    "title": "El mejor libro",
    "section": "¿Cuántas páginas debe tener nuestro libro?",
    "text": "¿Cuántas páginas debe tener nuestro libro?\nAhora, vamos a ver cómo de largo tiene que ser nuestro libro basándonos en las reviews de la gente.\n\nCódigop3 &lt;- goodreads %&gt;% \n  mutate (rang_pag = round(num_pages / 25) * 25) %&gt;% \n  group_by (rang_pag) %&gt;% \n  summarise (notita = weighted.mean(average_rating, w = ratings_count)) %&gt;% \n  ggplot (aes(x = rang_pag, y = notita)) +\n  geom_area (fill = \"#7831a2\") + \n  coord_cartesian (xlim = c(0, 1500), ylim = c(3, 5)) +\n  labs (title = \"Nota media por cada 50 páginas\",\n       x = \"Número de páginas\", y = \"Nota Media\")\n\np3\n\n\n\n\n\n\n\nCodigo inspirado de aquí.\nPodemos ver que el rango de mejores reviews está entorno a las 1.300 páginas por lo que nuestro libro tendrá que situarse en ese rango."
  },
  {
    "objectID": "my_trabajo_BigData.html#en-qué-idioma-debería-estar-nuestro-libro",
    "href": "my_trabajo_BigData.html#en-qué-idioma-debería-estar-nuestro-libro",
    "title": "El mejor libro",
    "section": "¿En qué idioma debería estar nuestro libro?",
    "text": "¿En qué idioma debería estar nuestro libro?\nPor último, queremos echar un vistazo a qué idiomas reciben mejores reviews para decidir en qué idioma debería escribirse nuestro libro para que sea el mejor. Para ello, realizaremos un gráfico de violín unificando todos los diferentes códigos de inglés para que cuenten como uno solo y filtrando los diez idiomas con mejor nota media.\n\nCódigotop_idioma &lt;- goodreads %&gt;% \n  mutate (language_code = fct_collapse(language_code,\n    \"eng\" = c(\"eng\", \"en-GB\", \"en-US\", \"en-CA\", \"enm\"))) %&gt;% \n  group_by (language_code) %&gt;% \n  summarise (media = weighted.mean(average_rating, w = ratings_count)) %&gt;% \n  arrange (desc(media)) %&gt;%\n  head (10) %&gt;% \n  pull(language_code) \n\np4 &lt;- goodreads %&gt;% \n  mutate (language_code = fct_collapse(language_code,\n    \"eng\" = c(\"eng\", \"en-GB\", \"en-US\", \"en-CA\", \"enm\"))) %&gt;% \n  filter (language_code %in% top_idioma) %&gt;% \n  ggplot (aes(x = reorder(language_code, -average_rating), y = average_rating)) + \n  geom_violin (fill = \"#7831a2\") +\n  coord_cartesian (ylim = c(3, 5)) +\n  labs (title = \"Nota media por idiomas\",\n       x = \"Idioma\", y = \"Nota Media\")\n\np4\n\n\n\n\n\n\n\nCodigo inspirado de aquí.\nSe puede observar que el idioma con mejor nota media es el chino. Sin embargo, para comprobar si realmente este idioma tiene tantos lectores potenciales, analizaremos cuáles son los idiomas más hablados.\n\nCódigotop_hablantes &lt;- hablantes %&gt;% \n  mutate (porcentaje = ((`Total Speakers`)/sum(`Total Speakers`))*100) %&gt;% \n  select (Language, porcentaje) %&gt;% \n  arrange (desc(porcentaje)) %&gt;%\n  head (10) \n\nhchart(top_hablantes, \"pie\", hcaes(x = Language, y = porcentaje))\n\n\n\n\n\nEste gráfico nos muestra que el chino es el segundo idioma más hablado, con muy poca diferencia respecto al primer puesto, que corresponde al inglés. Por lo tanto, escribiendo el libro en chino sí podríamos llegar a una audiencia muy amplia.\nDe esta manera, ¡¡hemos conseguido definir cómo debería ser el mejor libro del mundo!! Este debería ser un cómic o manga escrito por Bill Watterson, en chino, y de unas 1.300 páginas.\n\n¡Y hasta aquí mi trabajo de Big Data, espero que os haya gustado!\n\n\nUna foto mía"
  }
]